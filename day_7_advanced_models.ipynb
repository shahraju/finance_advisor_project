{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1f766f-cd72-42e0-8cab-3eedd4841478",
   "metadata": {},
   "source": [
    "# Day 7: Trying Advanced Models - Random Forest & Gradient Boosting\n",
    "\n",
    "In Day 6, we built a basic model.  \n",
    "Now, weâ€™ll try **Random Forest** and **Gradient Boosting**, two powerful ensemble methods.  \n",
    "Weâ€™ll evaluate their performance and save train-test splits for future experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed47d98-82ff-40d5-ada1-d207933e795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Random Forest â†’ MSE: 0.24  RÂ²: 0.98\n",
      "ðŸ”¹ Gradient Boosting â†’ MSE: 0.18  RÂ²: 0.99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "stock_data = pd.read_csv(\"synthetic_stock_data.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = stock_data[[\"open\", \"high\", \"low\", \"volume\"]]\n",
    "y = stock_data[\"close\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ---- Random Forest ----\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "# ---- Gradient Boosting ----\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "gb_mse = mean_squared_error(y_test, gb_preds)\n",
    "gb_r2 = r2_score(y_test, gb_preds)\n",
    "\n",
    "# ---- Print results ----\n",
    "print(\"ðŸ”¹ Random Forest â†’ MSE:\", round(rf_mse, 2), \" RÂ²:\", round(rf_r2, 2))\n",
    "print(\"ðŸ”¹ Gradient Boosting â†’ MSE:\", round(gb_mse, 2), \" RÂ²:\", round(gb_r2, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bdb31f-e979-47d1-8d48-2a4e4a420c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train-test splits saved for later use!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save train-test splits\n",
    "joblib.dump(X_train, \"X_train.pkl\")\n",
    "joblib.dump(X_test, \"X_test.pkl\")\n",
    "joblib.dump(y_train, \"y_train.pkl\")\n",
    "joblib.dump(y_test, \"y_test.pkl\")\n",
    "\n",
    "print(\"âœ… Train-test splits saved for later use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315333af-5047-4bf5-83e2-cc30740ef771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'best_gb_model.pkl', 'data', 'day_1_introduction.ipynb', 'day_2_data_creation.ipynb', 'day_3_eda.ipynb', 'day_4_feature_engineering.ipynb', 'day_5_baseline_model.ipynb', 'day_6_model_building.ipynb', 'day_7_advanced_models.ipynb', 'day_8_model_comparison.ipynb', 'day_9_hyperparameter_tuning.ipynb', 'notebooks', 'src', 'synthetic_stock_data.csv', 'synthetic_stock_data_with_features.csv', 'Untitled.ipynb', 'X_test.pkl', 'X_train.pkl', 'y_test.pkl', 'y_train.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8fa25-722d-48ee-8bfb-f40e6427d165",
   "metadata": {},
   "source": [
    "### âœ… Conclusion\n",
    "- Random Forest and Gradient Boosting both performed very well.  \n",
    "- Gradient Boosting achieved slightly better performance.  \n",
    "- We saved the train-test splits (`X_train.pkl`, `X_test.pkl`, `y_train.pkl`, `y_test.pkl`) for use in later experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8349f-bc62-4ffe-812f-2512fc20d8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
