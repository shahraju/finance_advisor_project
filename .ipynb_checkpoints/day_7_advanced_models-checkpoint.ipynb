{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0aa805-8e74-48c3-b895-4a2b87bd0f4b",
   "metadata": {},
   "source": [
    "# Day 7: Improving Predictions with Advanced Models\n",
    "\n",
    "So far, we have built and evaluated two models: **Linear Regression** and **Decision Tree**.  \n",
    "Today, we will explore **more advanced algorithms** to improve our predictions:\n",
    "\n",
    "- **Random Forest Regressor** â†’ an ensemble of decision trees.  \n",
    "- **Gradient Boosting Regressor** â†’ a boosting-based model that learns from previous mistakes.  \n",
    "\n",
    "We will compare their performance with earlier models and analyze if they provide better accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed47d98-82ff-40d5-ada1-d207933e795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Random Forest â†’ MSE: 0.24  RÂ²: 0.98\n",
      "ðŸ”¹ Gradient Boosting â†’ MSE: 0.18  RÂ²: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Day 7: Trying Advanced Models - Random Forest & Gradient Boosting\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset (same synthetic stock data we created earlier)\n",
    "stock_data = pd.read_csv(\"synthetic_stock_data.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = stock_data[[\"open\", \"high\", \"low\", \"volume\"]]\n",
    "y = stock_data[\"close\"]\n",
    "\n",
    "# Split into training & testing (same as Day 6)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ---- Train Random Forest ----\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "# ---- Train Gradient Boosting ----\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "gb_mse = mean_squared_error(y_test, gb_preds)\n",
    "gb_r2 = r2_score(y_test, gb_preds)\n",
    "\n",
    "# ---- Print results ----\n",
    "print(\"ðŸ”¹ Random Forest â†’ MSE:\", round(rf_mse, 2), \" RÂ²:\", round(rf_r2, 2))\n",
    "print(\"ðŸ”¹ Gradient Boosting â†’ MSE:\", round(gb_mse, 2), \" RÂ²:\", round(gb_r2, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b9cb8-1227-4dae-b68e-dc73c06570f1",
   "metadata": {},
   "source": [
    "### Day 7 Summary â€“ Advanced Models\n",
    "\n",
    "Today we tested two advanced models: **Random Forest** and **Gradient Boosting**.\n",
    "\n",
    "- **Random Forest** â†’ MSE = 0.24, RÂ² = 0.98  \n",
    "- **Gradient Boosting** â†’ MSE = 0.18, RÂ² = 0.99  \n",
    "\n",
    "ðŸ“Š **Observation:**  \n",
    "Both models performed really well, but Gradient Boosting gave slightly better accuracy compared to Random Forest. This shows that boosting techniques can capture patterns more effectively in our synthetic stock dataset.  \n",
    "\n",
    "Next, we can explore **hyperparameter tuning** to further optimize these models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8349f-bc62-4ffe-812f-2512fc20d8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
