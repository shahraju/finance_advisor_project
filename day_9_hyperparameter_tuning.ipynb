{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bccea9a0-2d8e-429d-8805-164338eaa852",
   "metadata": {},
   "source": [
    "# Day 9: Hyperparameter Tuning\n",
    "\n",
    "So far, we trained Random Forest and Gradient Boosting with default settings.  \n",
    "Today, we will perform **hyperparameter tuning** using `GridSearchCV` to find the best model configuration.  \n",
    "\n",
    "Steps:\n",
    "1. Load train-test splits from Day 7.  \n",
    "2. Define parameter grids for Random Forest and Gradient Boosting.  \n",
    "3. Run GridSearchCV to find the best hyperparameters.  \n",
    "4. Evaluate the best models on the test set.  \n",
    "5. Save the best-performing model for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110b6aad-6dfe-40ef-9f7b-c8bd26371782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train-test data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load train-test splits\n",
    "X_train = joblib.load(\"X_train.pkl\")\n",
    "X_test = joblib.load(\"X_test.pkl\")\n",
    "y_train = joblib.load(\"y_train.pkl\")\n",
    "y_test = joblib.load(\"y_test.pkl\")\n",
    "\n",
    "print(\"âœ… Train-test data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcd4e7d-1038-4760-b18c-9b685ba14d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Best RF Params: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "ðŸ”¹ Best RF CV Score: 0.28519176077257774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define parameter grid\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    rf_params,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"ðŸ”¹ Best RF Params:\", rf_grid.best_params_)\n",
    "print(\"ðŸ”¹ Best RF CV Score:\", -rf_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9cbc854-5de2-49ec-b170-fa30f3e8c9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Best GB Params: {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 200}\n",
      "ðŸ”¹ Best GB CV Score: 0.27374185355154196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Define parameter grid\n",
    "gb_params = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [2, 3, 4]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    gb_params,\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"ðŸ”¹ Best GB Params:\", gb_grid.best_params_)\n",
    "print(\"ðŸ”¹ Best GB CV Score:\", -gb_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525d945a-8591-4169-b7af-c6ec6ee077eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test Results after Hyperparameter Tuning\n",
      "Random Forest â†’ MSE: 0.23  RÂ²: 0.98\n",
      "Gradient Boosting â†’ MSE: 0.21  RÂ²: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate best RF\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_preds = best_rf.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "# Evaluate best GB\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_preds = best_gb.predict(X_test)\n",
    "gb_mse = mean_squared_error(y_test, gb_preds)\n",
    "gb_r2 = r2_score(y_test, gb_preds)\n",
    "\n",
    "print(\"âœ… Test Results after Hyperparameter Tuning\")\n",
    "print(\"Random Forest â†’ MSE:\", round(rf_mse, 2), \" RÂ²:\", round(rf_r2, 2))\n",
    "print(\"Gradient Boosting â†’ MSE:\", round(gb_mse, 2), \" RÂ²:\", round(gb_r2, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72c82b7-57ef-4f92-91fd-e76d47016eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŸ Best Model: Gradient Boosting saved as best_gb_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save best model (choose based on performance)\n",
    "if gb_mse < rf_mse:\n",
    "    joblib.dump(best_gb, \"best_gb_model.pkl\")\n",
    "    print(\"ðŸŒŸ Best Model: Gradient Boosting saved as best_gb_model.pkl\")\n",
    "else:\n",
    "    joblib.dump(best_rf, \"best_rf_model.pkl\")\n",
    "    print(\"ðŸŒŸ Best Model: Random Forest saved as best_rf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc341ac-2486-4ce6-8213-fe4e8567bad8",
   "metadata": {},
   "source": [
    "### âœ… Conclusion\n",
    "- Hyperparameter tuning improved both modelsâ€™ performance.  \n",
    "- Gradient Boosting generally performed slightly better.  \n",
    "- The **best model was saved** for future predictions (`best_gb_model.pkl` or `best_rf_model.pkl`).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149c194-7d11-4acd-8b27-03d3732c5ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
